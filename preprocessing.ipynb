{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sicom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0              قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...\n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...\n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...\n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./dataset/val.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    val = f.readlines()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[]{}[:()'\\\"]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"،\", \",\", text)\n",
    "    text = re.sub(r\"؟\", \"?\", text)\n",
    "    text = re.sub(r\"؛\", \";\", text)\n",
    "    return text\n",
    "\n",
    "val = \" \".join([clean_text(text) for text in val[:100]])\n",
    "val = sent_tokenize(val)\n",
    "sentences = []\n",
    "\n",
    "for sent in val:\n",
    "    sentences.extend(araby.sentence_tokenize(sent))\n",
    "df = pd.DataFrame(sentences)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .\n"
     ]
    }
   ],
   "source": [
    "print(df[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_cleaned</th>\n",
       "      <th>diacritics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .</td>\n",
       "      <td>[قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]</td>\n",
       "      <td>[قوله, ولا, تكره, ضيافته]</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "      <td>[الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...</td>\n",
       "      <td>[الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...</td>\n",
       "      <td>[[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "      <td>[قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...</td>\n",
       "      <td>[قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "      <td>[إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...</td>\n",
       "      <td>[إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...</td>\n",
       "      <td>[[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "      <td>[وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...</td>\n",
       "      <td>[وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...</td>\n",
       "      <td>[[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   \n",
       "0              قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .  \\\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...   \n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...   \n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...   \n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0           [قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]  \\\n",
       "1  [الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...   \n",
       "2  [قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...   \n",
       "3  [إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...   \n",
       "4  [وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...   \n",
       "\n",
       "                                   tokenized_cleaned   \n",
       "0                          [قوله, ولا, تكره, ضيافته]  \\\n",
       "1  [الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...   \n",
       "2  [قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...   \n",
       "3  [إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...   \n",
       "4  [وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...   \n",
       "\n",
       "                                          diacritics  \n",
       "0  [[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...  \n",
       "1  [[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...  \n",
       "2  [[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...  \n",
       "3  [[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...  \n",
       "4  [[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import unicodedata\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def condition(word):\n",
    "    # if len(word) == 1:\n",
    "    #     if word == \"و\":\n",
    "    #         return True\n",
    "    #     return False\n",
    "    return araby.is_arabicrange(word)\n",
    "\n",
    "\n",
    "diacritic_to_id = pickle.load(open(\"./assets/diacritic2id.pickle\", \"rb\"))\n",
    "arabic_letters = list(pickle.load(open(\"./assets/arabic_letters.pickle\", \"rb\")))\n",
    "\n",
    "\n",
    "\n",
    "def extract_diacritics(text):\n",
    "    diacritics_list = []\n",
    "    for word in text:\n",
    "        word_list = []\n",
    "        for idx, char in enumerate(word):        \n",
    "            if char in diacritic_to_id:\n",
    "                continue\n",
    "            if char not in arabic_letters:\n",
    "                continue\n",
    "            \n",
    "            if idx + 2 >= len(word): # last char\n",
    "                if idx == len(word) - 1:\n",
    "                    word_list.append(diacritic_to_id[\"\"])\n",
    "                    break\n",
    "                if word[idx+1] in diacritic_to_id:\n",
    "                    word_list.append(diacritic_to_id[word[idx+1]])\n",
    "                    break\n",
    "                else:\n",
    "                    word_list.append(diacritic_to_id[\"\"])\n",
    "                    continue\n",
    "\n",
    "            \n",
    "            if word[idx+1] in diacritic_to_id and word[idx+2] in diacritic_to_id:\n",
    "                if diacritic_to_id[word[idx+1]] == 7:\n",
    "                    word_list.append(diacritic_to_id[word[idx+2]]+8) \n",
    "                else:\n",
    "                    word_list.append(diacritic_to_id[\"\"])    \n",
    "            elif word[idx+1] in diacritic_to_id and word[idx+2] not in diacritic_to_id:\n",
    "                word_list.append(diacritic_to_id[word[idx+1]])\n",
    "            else:\n",
    "                word_list.append(diacritic_to_id[\"\"])\n",
    "        diacritics_list.append(word_list)\n",
    "                \n",
    "        \n",
    "\n",
    "    return diacritics_list\n",
    "\n",
    "\n",
    "df[\"tokenized\"] = df[0].apply(lambda sent: araby.tokenize(sent, conditions=condition))\n",
    "df[\"tokenized_cleaned\"] = df[0].apply(lambda sent: araby.tokenize(sent, conditions=condition, morphs=araby.strip_tashkeel))\n",
    "df[\"diacritics\"] = df[\"tokenized\"].apply(extract_diacritics)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 14, 14, 8, 0, 14, 2, 14, 0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_diacritics([\"وَالثَّلَاثُونَ\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feauture extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diacritics_probability_per_char(tokenized_cleaned, diacritics): \n",
    "    probability = {}\n",
    "    \n",
    "    for i in range(36):\n",
    "        probability[i] = []\n",
    "        for j in range(15):\n",
    "            probability[i].append(0)\n",
    "            \n",
    "    counts = [0]*36\n",
    "            \n",
    "    for i in range(len(tokenized_cleaned)):\n",
    "        for j in range(len(tokenized_cleaned[i])):\n",
    "            for k in range(len(tokenized_cleaned[i][j])):\n",
    "                probability[arabic_letters.index(tokenized_cleaned[i][j][k])][diacritics[i][j][k]] += 1\n",
    "                counts[arabic_letters.index(tokenized_cleaned[i][j][k])] += 1\n",
    "            \n",
    "            \n",
    "    for i in range(36):\n",
    "        for j in range(15):\n",
    "            probability[i][j] /= counts[i]\n",
    "        \n",
    "    return probability\n",
    "\n",
    "def create_bef_after(text):\n",
    "    input_vectors = []\n",
    "    if len(text) == 1:\n",
    "        letter_vec = []\n",
    "        letter_vec.append(36)\n",
    "        letter_vec.append(36)\n",
    "        input_vectors.append(letter_vec)\n",
    "        return input_vectors\n",
    "    for i in range(len(text)):\n",
    "        letter_vec = []\n",
    "        if i == 0:\n",
    "            letter_vec.append(36)\n",
    "            letter_vec.append(arabic_letters.index(text[i+1]))\n",
    "            input_vectors.append(letter_vec)\n",
    "            continue\n",
    "        elif i == len(text)-1:\n",
    "            letter_vec.append(arabic_letters.index(text[i-1]))\n",
    "\n",
    "            letter_vec.append(36)\n",
    "            input_vectors.append(letter_vec)\n",
    "            break\n",
    "        letter_vec.append(arabic_letters.index(text[i-1]))\n",
    "\n",
    "        letter_vec.append(arabic_letters.index(text[i+1]))\n",
    "        input_vectors.append(letter_vec)\n",
    "    \n",
    "    \n",
    "    return input_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_cleaned</th>\n",
       "      <th>diacritics</th>\n",
       "      <th>prob_per_char</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .</td>\n",
       "      <td>[قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]</td>\n",
       "      <td>[قوله, ولا, تكره, ضيافته]</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "      <td>[الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...</td>\n",
       "      <td>[الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...</td>\n",
       "      <td>[[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...</td>\n",
       "      <td>[[[0.4327186818027109, 0.007387831100967025, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "      <td>[قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...</td>\n",
       "      <td>[قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "      <td>[إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...</td>\n",
       "      <td>[إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...</td>\n",
       "      <td>[[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...</td>\n",
       "      <td>[[[0.25205920929361064, 0.0018512272812441447,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "      <td>[وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...</td>\n",
       "      <td>[وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...</td>\n",
       "      <td>[[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...</td>\n",
       "      <td>[[[0.4627733688738111, 0.005755134185497062, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   \n",
       "0              قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .  \\\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...   \n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...   \n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...   \n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0           [قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]  \\\n",
       "1  [الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...   \n",
       "2  [قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...   \n",
       "3  [إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...   \n",
       "4  [وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...   \n",
       "\n",
       "                                   tokenized_cleaned   \n",
       "0                          [قوله, ولا, تكره, ضيافته]  \\\n",
       "1  [الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...   \n",
       "2  [قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...   \n",
       "3  [إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...   \n",
       "4  [وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...   \n",
       "\n",
       "                                          diacritics   \n",
       "0  [[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...  \\\n",
       "1  [[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...   \n",
       "2  [[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...   \n",
       "3  [[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...   \n",
       "4  [[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...   \n",
       "\n",
       "                                       prob_per_char  \n",
       "0  [[[0.3664743069249507, 0.011585082937014268, 0...  \n",
       "1  [[[0.4327186818027109, 0.007387831100967025, 0...  \n",
       "2  [[[0.3664743069249507, 0.011585082937014268, 0...  \n",
       "3  [[[0.25205920929361064, 0.0018512272812441447,...  \n",
       "4  [[[0.4627733688738111, 0.005755134185497062, 0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_per_char = pickle.load(open(\"./assets/prob_dict.pkl\", \"rb\"))\n",
    "df[\"prob_per_char\"] = df[\"tokenized_cleaned\"].apply(lambda x: [[prob_per_char[list(arabic_letters).index(char)] for char in word] for word in x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bef_after\"] = df[\"tokenized_cleaned\"].apply(lambda x: [create_bef_after(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_cleaned</th>\n",
       "      <th>diacritics</th>\n",
       "      <th>prob_per_char</th>\n",
       "      <th>bef_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .</td>\n",
       "      <td>[قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]</td>\n",
       "      <td>[قوله, ولا, تكره, ضيافته]</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "      <td>[[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "      <td>[الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...</td>\n",
       "      <td>[الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...</td>\n",
       "      <td>[[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...</td>\n",
       "      <td>[[[0.4327186818027109, 0.007387831100967025, 0...</td>\n",
       "      <td>[[[36, 19], [25, 10], [19, 27], [10, 6], [27, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "      <td>[قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...</td>\n",
       "      <td>[قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "      <td>[[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "      <td>[إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...</td>\n",
       "      <td>[إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...</td>\n",
       "      <td>[[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...</td>\n",
       "      <td>[[[0.25205920929361064, 0.0018512272812441447,...</td>\n",
       "      <td>[[[36, 7], [0, 36]], [[36, 19], [25, 11], [19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "      <td>[وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...</td>\n",
       "      <td>[وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...</td>\n",
       "      <td>[[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...</td>\n",
       "      <td>[[[0.4627733688738111, 0.005755134185497062, 0...</td>\n",
       "      <td>[[[36, 6], [31, 13], [6, 36]], [[36, 22], [20,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   \n",
       "0              قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .  \\\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...   \n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...   \n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...   \n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0           [قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]  \\\n",
       "1  [الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...   \n",
       "2  [قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...   \n",
       "3  [إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...   \n",
       "4  [وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...   \n",
       "\n",
       "                                   tokenized_cleaned   \n",
       "0                          [قوله, ولا, تكره, ضيافته]  \\\n",
       "1  [الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...   \n",
       "2  [قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...   \n",
       "3  [إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...   \n",
       "4  [وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...   \n",
       "\n",
       "                                          diacritics   \n",
       "0  [[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...  \\\n",
       "1  [[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...   \n",
       "2  [[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...   \n",
       "3  [[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...   \n",
       "4  [[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...   \n",
       "\n",
       "                                       prob_per_char   \n",
       "0  [[[0.3664743069249507, 0.011585082937014268, 0...  \\\n",
       "1  [[[0.4327186818027109, 0.007387831100967025, 0...   \n",
       "2  [[[0.3664743069249507, 0.011585082937014268, 0...   \n",
       "3  [[[0.25205920929361064, 0.0018512272812441447,...   \n",
       "4  [[[0.4627733688738111, 0.005755134185497062, 0...   \n",
       "\n",
       "                                           bef_after  \n",
       "0  [[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...  \n",
       "1  [[[36, 19], [25, 10], [19, 27], [10, 6], [27, ...  \n",
       "2  [[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...  \n",
       "3  [[[36, 7], [0, 36]], [[36, 19], [25, 11], [19,...  \n",
       "4  [[[36, 6], [31, 13], [6, 36]], [[36, 22], [20,...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featuers Concatination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_cleaned</th>\n",
       "      <th>diacritics</th>\n",
       "      <th>prob_per_char</th>\n",
       "      <th>bef_after</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .</td>\n",
       "      <td>[قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]</td>\n",
       "      <td>[قوله, ولا, تكره, ضيافته]</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "      <td>[[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "      <td>[الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...</td>\n",
       "      <td>[الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...</td>\n",
       "      <td>[[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...</td>\n",
       "      <td>[[[0.4327186818027109, 0.007387831100967025, 0...</td>\n",
       "      <td>[[[36, 19], [25, 10], [19, 27], [10, 6], [27, ...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "      <td>[قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...</td>\n",
       "      <td>[قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "      <td>[[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "      <td>[إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...</td>\n",
       "      <td>[إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...</td>\n",
       "      <td>[[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...</td>\n",
       "      <td>[[[0.25205920929361064, 0.0018512272812441447,...</td>\n",
       "      <td>[[[36, 7], [0, 36]], [[36, 19], [25, 11], [19,...</td>\n",
       "      <td>[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "      <td>[وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...</td>\n",
       "      <td>[وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...</td>\n",
       "      <td>[[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...</td>\n",
       "      <td>[[[0.4627733688738111, 0.005755134185497062, 0...</td>\n",
       "      <td>[[[36, 6], [31, 13], [6, 36]], [[36, 22], [20,...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   \n",
       "0              قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .  \\\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...   \n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...   \n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...   \n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0           [قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]  \\\n",
       "1  [الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...   \n",
       "2  [قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...   \n",
       "3  [إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...   \n",
       "4  [وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...   \n",
       "\n",
       "                                   tokenized_cleaned   \n",
       "0                          [قوله, ولا, تكره, ضيافته]  \\\n",
       "1  [الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...   \n",
       "2  [قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...   \n",
       "3  [إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...   \n",
       "4  [وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...   \n",
       "\n",
       "                                          diacritics   \n",
       "0  [[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...  \\\n",
       "1  [[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...   \n",
       "2  [[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...   \n",
       "3  [[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...   \n",
       "4  [[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...   \n",
       "\n",
       "                                       prob_per_char   \n",
       "0  [[[0.3664743069249507, 0.011585082937014268, 0...  \\\n",
       "1  [[[0.4327186818027109, 0.007387831100967025, 0...   \n",
       "2  [[[0.3664743069249507, 0.011585082937014268, 0...   \n",
       "3  [[[0.25205920929361064, 0.0018512272812441447,...   \n",
       "4  [[[0.4627733688738111, 0.005755134185497062, 0...   \n",
       "\n",
       "                                           bef_after   \n",
       "0  [[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...  \\\n",
       "1  [[[36, 19], [25, 10], [19, 27], [10, 6], [27, ...   \n",
       "2  [[[36, 31], [6, 19], [31, 3], [19, 36]], [[36,...   \n",
       "3  [[[36, 7], [0, 36]], [[36, 19], [25, 11], [19,...   \n",
       "4  [[[36, 6], [31, 13], [6, 36]], [[36, 22], [20,...   \n",
       "\n",
       "                                            features  \n",
       "0  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...  \n",
       "1  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...  \n",
       "3  [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "4  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def concat_features(tokenized_cleaned, prob, bef_after):\n",
    "    features = []\n",
    "    for idx, word in enumerate(tokenized_cleaned):\n",
    "        word_features = []\n",
    "        for letter_idx, letter in enumerate(word):\n",
    "            letter_id = arabic_letters.index(letter)\n",
    "            feature = np.zeros(36)\n",
    "            feature[letter_id] = 1\n",
    "            feature = list(feature)\n",
    "            feature.extend(prob[idx][letter_idx])\n",
    "            feature.extend(bef_after[idx][letter_idx])\n",
    "            word_features.append(feature)\n",
    "        features.append(word_features)\n",
    "    return features\n",
    "\n",
    "df[\"features\"] = df.apply(lambda x: concat_features(x[\"tokenized_cleaned\"], x[\"prob_per_char\"], x[\"bef_after\"]), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3664743069249507,\n",
       "  0.011585082937014268,\n",
       "  0.2506089780767892,\n",
       "  0.00929416541004524,\n",
       "  0.09916193017051386,\n",
       "  0.010671615821830413,\n",
       "  0.14548776244055214,\n",
       "  0.0003334879944322004,\n",
       "  0.08128407377334416,\n",
       "  4.349843405637397e-05,\n",
       "  0.014803967057185941,\n",
       "  0.00013049530216912192,\n",
       "  0.0061042802459111475,\n",
       "  7.249739009395662e-05,\n",
       "  0.00394385802111124,\n",
       "  36,\n",
       "  31],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4627733688738111,\n",
       "  0.005755134185497062,\n",
       "  0.15102683709941236,\n",
       "  0.004058884109771612,\n",
       "  0.13836554189131883,\n",
       "  0.008723571818016598,\n",
       "  0.11958563033864421,\n",
       "  0.0011510268370994124,\n",
       "  0.07166656569940025,\n",
       "  0.00042406251893136246,\n",
       "  0.021203125946568122,\n",
       "  0.0005452232386260374,\n",
       "  0.014115223844429635,\n",
       "  0.00036348215908402497,\n",
       "  0.00024232143938934998,\n",
       "  6,\n",
       "  19],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.38516363986009783,\n",
       "  0.014326750880398071,\n",
       "  0.11815062318962513,\n",
       "  0.018043653321474503,\n",
       "  0.2220496147882838,\n",
       "  0.030116825518924053,\n",
       "  0.12358024542974243,\n",
       "  0.0009735459910337616,\n",
       "  0.05424814605593683,\n",
       "  0.0011388084277833199,\n",
       "  0.012902489152774607,\n",
       "  0.0020222112714991408,\n",
       "  0.015420487734522422,\n",
       "  0.0014362808139325247,\n",
       "  0.00042667756397158686,\n",
       "  31,\n",
       "  3],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6461516586641,\n",
       "  0.003685920222248958,\n",
       "  0.0564044231042667,\n",
       "  0.0013890559888000524,\n",
       "  0.13278062759080816,\n",
       "  0.013485874284964288,\n",
       "  0.10972448566647344,\n",
       "  0.0002187489746141815,\n",
       "  0.020146780561966116,\n",
       "  0.00019687407715276336,\n",
       "  0.004199980312592284,\n",
       "  0.00020781152588347242,\n",
       "  0.011178072602784675,\n",
       "  0.00010937448730709074,\n",
       "  0.00012031193603779982,\n",
       "  19,\n",
       "  36]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.features[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed/train_shwya.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_cleaned</th>\n",
       "      <th>diacritics</th>\n",
       "      <th>prob_per_char</th>\n",
       "      <th>bef_after</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- حَدَّثَنَا أَحْمَدُ بْنُ عَبْدِ الْمَلِكِ حَ...</td>\n",
       "      <td>[حَدَّثَنَا, أَحْمَدُ, بْنُ, عَبْدِ, الْمَلِكِ...</td>\n",
       "      <td>[حدثنا, أحمد, بن, عبد, الملك, حدثنا, محمد, بن,...</td>\n",
       "      <td>[[0, 8, 0, 0, 14], [0, 6, 0, 2], [6, 2], [0, 6...</td>\n",
       "      <td>[[[0.2501540319400631, 0.006689093717139853, 0...</td>\n",
       "      <td>[[[36, 11], [2, 0], [11, 29], [0, 24], [29, 36...</td>\n",
       "      <td>[[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/   وَقَالَ خَلِيفَةُ عَاشَ إِحْدَى وَخَمْسِين...</td>\n",
       "      <td>[وَقَالَ, خَلِيفَةُ, عَاشَ, إِحْدَى, وَخَمْسِي...</td>\n",
       "      <td>[وقال, خليفة, عاش, إحدى, وخمسين, سنة]</td>\n",
       "      <td>[[0, 0, 14, 0], [0, 4, 14, 0, 2], [0, 14, 0], ...</td>\n",
       "      <td>[[[0.35878333333333334, 0.05773333333333333, 0...</td>\n",
       "      <td>[[[36, 18], [15, 24], [18, 13], [24, 36]], [[3...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- حَدَّثَنَا سُفْيَانُ حَدَّثَنِي مُسْلِمُ بْن...</td>\n",
       "      <td>[حَدَّثَنَا, سُفْيَانُ, حَدَّثَنِي, مُسْلِمُ, ...</td>\n",
       "      <td>[حدثنا, سفيان, حدثني, مسلم, بن, أبي, مريم, عن,...</td>\n",
       "      <td>[[0, 8, 0, 0, 14], [2, 6, 0, 14, 2], [0, 8, 0,...</td>\n",
       "      <td>[[[0.2501540319400631, 0.006689093717139853, 0...</td>\n",
       "      <td>[[[36, 11], [2, 0], [11, 29], [0, 24], [29, 36...</td>\n",
       "      <td>[[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>لِأَنَّهُ مَعْصِيَةٌ ,</td>\n",
       "      <td>[لِأَنَّهُ, مَعْصِيَةٌ]</td>\n",
       "      <td>[لأنه, معصية]</td>\n",
       "      <td>[[4, 0, 8, 2], [0, 6, 4, 0, 3]]</td>\n",
       "      <td>[[[0.003846002388984419, 0.0, 2.62525760340233...</td>\n",
       "      <td>[[[36, 19], [13, 29], [19, 32], [29, 36]], [[3...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَكَذَلِكَ إذَا اسْتَأْجَرَهَا ذِمِّيٌّ مِنْ ذ...</td>\n",
       "      <td>[وَكَذَلِكَ, إذَا, اسْتَأْجَرَهَا, ذِمِّيٌّ, م...</td>\n",
       "      <td>[وكذلك, إذا, استأجرها, ذمي, من, ذمي]</td>\n",
       "      <td>[[0, 0, 0, 4, 0], [14, 0, 14], [14, 6, 0, 6, 0...</td>\n",
       "      <td>[[[0.35878333333333334, 0.05773333333333333, 0...</td>\n",
       "      <td>[[[36, 9], [15, 23], [9, 13], [23, 9], [13, 36...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   \n",
       "0  - حَدَّثَنَا أَحْمَدُ بْنُ عَبْدِ الْمَلِكِ حَ...  \\\n",
       "1  /   وَقَالَ خَلِيفَةُ عَاشَ إِحْدَى وَخَمْسِين...   \n",
       "2  - حَدَّثَنَا سُفْيَانُ حَدَّثَنِي مُسْلِمُ بْن...   \n",
       "3                             لِأَنَّهُ مَعْصِيَةٌ ,   \n",
       "4  وَكَذَلِكَ إذَا اسْتَأْجَرَهَا ذِمِّيٌّ مِنْ ذ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0  [حَدَّثَنَا, أَحْمَدُ, بْنُ, عَبْدِ, الْمَلِكِ...  \\\n",
       "1  [وَقَالَ, خَلِيفَةُ, عَاشَ, إِحْدَى, وَخَمْسِي...   \n",
       "2  [حَدَّثَنَا, سُفْيَانُ, حَدَّثَنِي, مُسْلِمُ, ...   \n",
       "3                            [لِأَنَّهُ, مَعْصِيَةٌ]   \n",
       "4  [وَكَذَلِكَ, إذَا, اسْتَأْجَرَهَا, ذِمِّيٌّ, م...   \n",
       "\n",
       "                                   tokenized_cleaned   \n",
       "0  [حدثنا, أحمد, بن, عبد, الملك, حدثنا, محمد, بن,...  \\\n",
       "1              [وقال, خليفة, عاش, إحدى, وخمسين, سنة]   \n",
       "2  [حدثنا, سفيان, حدثني, مسلم, بن, أبي, مريم, عن,...   \n",
       "3                                      [لأنه, معصية]   \n",
       "4               [وكذلك, إذا, استأجرها, ذمي, من, ذمي]   \n",
       "\n",
       "                                          diacritics   \n",
       "0  [[0, 8, 0, 0, 14], [0, 6, 0, 2], [6, 2], [0, 6...  \\\n",
       "1  [[0, 0, 14, 0], [0, 4, 14, 0, 2], [0, 14, 0], ...   \n",
       "2  [[0, 8, 0, 0, 14], [2, 6, 0, 14, 2], [0, 8, 0,...   \n",
       "3                    [[4, 0, 8, 2], [0, 6, 4, 0, 3]]   \n",
       "4  [[0, 0, 0, 4, 0], [14, 0, 14], [14, 6, 0, 6, 0...   \n",
       "\n",
       "                                       prob_per_char   \n",
       "0  [[[0.2501540319400631, 0.006689093717139853, 0...  \\\n",
       "1  [[[0.35878333333333334, 0.05773333333333333, 0...   \n",
       "2  [[[0.2501540319400631, 0.006689093717139853, 0...   \n",
       "3  [[[0.003846002388984419, 0.0, 2.62525760340233...   \n",
       "4  [[[0.35878333333333334, 0.05773333333333333, 0...   \n",
       "\n",
       "                                           bef_after   \n",
       "0  [[[36, 11], [2, 0], [11, 29], [0, 24], [29, 36...  \\\n",
       "1  [[[36, 18], [15, 24], [18, 13], [24, 36]], [[3...   \n",
       "2  [[[36, 11], [2, 0], [11, 29], [0, 24], [29, 36...   \n",
       "3  [[[36, 19], [13, 29], [19, 32], [29, 36]], [[3...   \n",
       "4  [[[36, 9], [15, 23], [9, 13], [23, 9], [13, 36...   \n",
       "\n",
       "                                            features  \n",
       "0  [[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "1  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2  [[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "3  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "4  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' َ', 0),\n",
       " (' ً', 1),\n",
       " (' ُ', 2),\n",
       " (' ٌ', 3),\n",
       " (' ِ', 4),\n",
       " (' ٍ', 5),\n",
       " (' ْ', 6),\n",
       " (' ّ', 7),\n",
       " (' َّ', 8),\n",
       " (' ًّ', 9),\n",
       " (' ُّ', 10),\n",
       " (' ٌّ', 11),\n",
       " (' ِّ', 12),\n",
       " (' ٍّ', 13),\n",
       " (' ', 14)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "diacritic_to_id = pickle.load(open(\"./assets/diacritic2id.pickle\", \"rb\"))\n",
    "\n",
    "[ (\" \" + x, idx) for idx, x in enumerate(diacritic_to_id.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "# ignore\n",
    "class Model(nn.Module):\n",
    "  def __init__(self, input_size=768, hidden_size=50, n_classes=100):\n",
    "\n",
    "    super(Model, self).__init__()\n",
    "\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=0.2)\n",
    "\n",
    "    self.linear = nn.Linear(hidden_size, n_classes)\n",
    "\n",
    "  def forward(self, X, hidden=None):\n",
    "\n",
    "    final_output, hidden = self.lstm(X, hidden)\n",
    "    final_output = self.linear(final_output)\n",
    "\n",
    "    return final_output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "context_model = pickle.load(open(\"./models/context_model.pkl\", \"rb\")).to(device)\n",
    "context_model.lstm.flatten_parameters()\n",
    "tokenizer = AutoTokenizer.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca')\n",
    "embedder = AutoModel.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca').to(device)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/347 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [00:21<00:00, 15.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_contextualized_embeddings(sent):\n",
    "    if len(sent) == 0:\n",
    "        return []\n",
    "    tokens = tokenizer(sent, return_tensors=\"pt\", padding=True)\n",
    "    tokens = tokens.to(device)\n",
    "    embeddings = embedder(**tokens).last_hidden_state[:, 1, :]\n",
    "    hidden_layers = []    \n",
    "    with torch.no_grad():\n",
    "        hidden = None\n",
    "        for embedding in embeddings:\n",
    "            _, hidden = context_model(embedding.unsqueeze(0), hidden)\n",
    "            hidden_layers.append(hidden[0])\n",
    "\n",
    "    return list(zip(sent, hidden_layers))\n",
    "\n",
    "df[\"tokens_with_context\"] = df[\"tokenized_cleaned\"].progress_apply(get_contextualized_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_cleaned</th>\n",
       "      <th>diacritics</th>\n",
       "      <th>prob_per_char</th>\n",
       "      <th>bef_after</th>\n",
       "      <th>features</th>\n",
       "      <th>tokens_with_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .</td>\n",
       "      <td>[قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]</td>\n",
       "      <td>[قوله, ولا, تكره, ضيافته]</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "      <td>[[[36, 28], [6, 35], [28, 11], [35, 36]], [[36...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...</td>\n",
       "      <td>[(قوله, [tensor([-5.7860e-05,  7.6122e-01,  3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "      <td>[الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...</td>\n",
       "      <td>[الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...</td>\n",
       "      <td>[[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...</td>\n",
       "      <td>[[[0.4327186818027109, 0.007387831100967025, 0...</td>\n",
       "      <td>[[[36, 35], [25, 4], [35, 21], [4, 6], [21, 36...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[(الفرق, [tensor([-8.2446e-06,  7.6140e-01,  2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "      <td>[قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...</td>\n",
       "      <td>[قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...</td>\n",
       "      <td>[[[0.3664743069249507, 0.011585082937014268, 0...</td>\n",
       "      <td>[[[36, 28], [6, 35], [28, 11], [35, 36]], [[36...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...</td>\n",
       "      <td>[(قوله, [tensor([-5.7860e-05,  7.6122e-01,  3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "      <td>[إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...</td>\n",
       "      <td>[إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...</td>\n",
       "      <td>[[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...</td>\n",
       "      <td>[[[0.6461516586641, 0.003685920222248958, 0.05...</td>\n",
       "      <td>[[[36, 32], [3, 36]], [[36, 35], [25, 19], [35...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[(إذ, [tensor([-2.3214e-05,  7.6133e-01,  4.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "      <td>[وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...</td>\n",
       "      <td>[وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...</td>\n",
       "      <td>[[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...</td>\n",
       "      <td>[[[0.412407786468069, 0.006399887474505943, 0....</td>\n",
       "      <td>[[[36, 6], [28, 16], [6, 36]], [[36, 34], [5, ...</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[(وقد, [tensor([-3.2933e-04,  7.6013e-01,  7.6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   \n",
       "0              قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .  \\\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...   \n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...   \n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...   \n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0           [قَوْلُهُ, وَلَا, تُكْرَهُ, ضِيَافَتُهُ]  \\\n",
       "1  [الْفَرْقُ, الثَّالِثُ, وَالثَّلَاثُونَ, بَيْن...   \n",
       "2  [قَوْلُهُ, وَهُوَ, أَيْ, الْبَيْعُ, بِالْمَعْن...   \n",
       "3  [إذْ, الْمُقَابَلَةُ, لَا, تَصْدُقُ, عَلَى, ال...   \n",
       "4  [وَقَدْ, يُجْعَلُ, كَلَامُهُ, عَلَى, حَذْفِ, م...   \n",
       "\n",
       "                                   tokenized_cleaned   \n",
       "0                          [قوله, ولا, تكره, ضيافته]  \\\n",
       "1  [الفرق, الثالث, والثلاثون, بين, قاعدة, تقدم, ا...   \n",
       "2  [قوله, وهو, أي, البيع, بالمعنى, الثاني, الذي, ...   \n",
       "3  [إذ, المقابلة, لا, تصدق, على, العقد, فكان, الم...   \n",
       "4  [وقد, يجعل, كلامه, على, حذف, مضاف, أي, ذو, مقا...   \n",
       "\n",
       "                                          diacritics   \n",
       "0  [[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...  \\\n",
       "1  [[14, 6, 0, 6, 2], [14, 14, 8, 14, 4, 2], [0, ...   \n",
       "2  [[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...   \n",
       "3  [[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...   \n",
       "4  [[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...   \n",
       "\n",
       "                                       prob_per_char   \n",
       "0  [[[0.3664743069249507, 0.011585082937014268, 0...  \\\n",
       "1  [[[0.4327186818027109, 0.007387831100967025, 0...   \n",
       "2  [[[0.3664743069249507, 0.011585082937014268, 0...   \n",
       "3  [[[0.6461516586641, 0.003685920222248958, 0.05...   \n",
       "4  [[[0.412407786468069, 0.006399887474505943, 0....   \n",
       "\n",
       "                                           bef_after   \n",
       "0  [[[36, 28], [6, 35], [28, 11], [35, 36]], [[36...  \\\n",
       "1  [[[36, 35], [25, 4], [35, 21], [4, 6], [21, 36...   \n",
       "2  [[[36, 28], [6, 35], [28, 11], [35, 36]], [[36...   \n",
       "3  [[[36, 32], [3, 36]], [[36, 35], [25, 19], [35...   \n",
       "4  [[[36, 6], [28, 16], [6, 36]], [[36, 34], [5, ...   \n",
       "\n",
       "                                            features   \n",
       "0  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...  \\\n",
       "1  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...   \n",
       "3  [[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "\n",
       "                                 tokens_with_context  \n",
       "0  [(قوله, [tensor([-5.7860e-05,  7.6122e-01,  3....  \n",
       "1  [(الفرق, [tensor([-8.2446e-06,  7.6140e-01,  2...  \n",
       "2  [(قوله, [tensor([-5.7860e-05,  7.6122e-01,  3....  \n",
       "3  [(إذ, [tensor([-2.3214e-05,  7.6133e-01,  4.03...  \n",
       "4  [(وقد, [tensor([-3.2933e-04,  7.6013e-01,  7.6...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
