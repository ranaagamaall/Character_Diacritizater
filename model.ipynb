{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle \n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, y, pad_x, pad_y):\n",
    "    \"\"\"\n",
    "    This is the constructor of the NERDataset\n",
    "    Inputs:\n",
    "    - x: a list of lists where each list contains the ids of the tokens\n",
    "    - y: a list of lists where each list contains the label of each token in the sentence\n",
    "    - pad: the id of the <PAD> token (to be used for padding all sentences and labels to have the same length)\n",
    "    \"\"\"\n",
    "    ##################### TODO: create two tensors one for x and the other for labels ###############################\n",
    "    self.data = torch.tensor(x)\n",
    "    self.labels = torch.tensor(y)\n",
    "\n",
    "    max_len = max([len(sentence) for sentence in x])\n",
    "    for i in range(len(x)):\n",
    "      x[i] = x[i] + [pad_x] * (max_len - len(x[i]))\n",
    "      y[i] = y[i] + [pad_y] * (max_len - len(y[i]))\n",
    "    #################################################################################################################\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    This function should return the length of the dataset (the number of sentences)\n",
    "    \"\"\"\n",
    "    ###################### TODO: return the length of the dataset #############################\n",
    "    return len(self.data)\n",
    "    ###########################################################################################\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    This function returns a subset of the whole dataset\n",
    "    \"\"\"\n",
    "    ###################### TODO: return a tuple of x and y ###################################\n",
    "    return self.data[idx], self.labels[idx]\n",
    "    ##########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NER(nn.Module):\n",
    "  def __init__(self, vocab_size=35181, embedding_dim=50, hidden_size=50, n_classes=12):\n",
    "    \"\"\"\n",
    "    The constructor of our NER model\n",
    "    Inputs:\n",
    "    - vacab_size: the number of unique words\n",
    "    - embedding_dim: the embedding dimension\n",
    "    - n_classes: the number of final classes (tags)\n",
    "    \"\"\"\n",
    "    super(NER, self).__init__()\n",
    "    ####################### TODO: Create the layers of your model #######################################\n",
    "    # (1) Create the embedding layer\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "    # (2) Create an LSTM layer with hidden size = hidden_size and batch_first = True\n",
    "    self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True)\n",
    "\n",
    "    # (3) Create a linear layer with number of neorons = n_classes\n",
    "    self.linear = nn.Linear(hidden_size, n_classes)\n",
    "    #####################################################################################################\n",
    "\n",
    "  def forward(self, sentences):\n",
    "    \"\"\"\n",
    "    This function does the forward pass of our model\n",
    "    Inputs:\n",
    "    - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "    Returns:\n",
    "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    final_output = None\n",
    "    ######################### TODO: implement the forward pass ####################################\n",
    "    embeddings = self.embedding(sentences)\n",
    "    lstm_out, _ = self.lstm(embeddings)\n",
    "    final_output = self.linear(lstm_out)\n",
    "    \n",
    "    ###############################################################################################\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ml_Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Torch_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers, bidirectional=False, type='RNN', dropout=0.0):\n",
    "        super(Torch_Model, self).__init__()\n",
    "        self.num_layers = num_layers if not bidirectional else num_layers*2\n",
    "        self.hidden_to_output_size = hidden_size if not bidirectional else hidden_size*2\n",
    "        self.hidden_size = hidden_size\n",
    "        if type == 'RNN':\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, self.num_layers,\n",
    "                               bidirectional=bidirectional, batch_first=True, dropout=dropout)\n",
    "        elif type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, self.num_layers,\n",
    "                                bidirectional=bidirectional,batch_first=True, dropout=dropout)\n",
    "        elif type == 'GRU':\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, self.num_layers,\n",
    "                               bidirectional=bidirectional,batch_first=True, dropout=dropout)\n",
    "        # -> x needs to be: (batch_size, seq, input_size)\n",
    "\n",
    "        self.hidden_to_output = nn.Linear(self.hidden_to_output_size, num_classes)\n",
    "        # self.soft_max = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        # Set initial hidden states (and cell states for LSTM)\n",
    "        if hidden is None:\n",
    "            if isinstance(self.rnn, nn.LSTM):\n",
    "                # hidden = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "                hidden = (torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device),\n",
    "                           torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device))\n",
    "            else:\n",
    "                hidden = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        \n",
    "        h_out, hidden_out = self.rnn(x, hidden)\n",
    "        \n",
    "        h_out = h_out[:, -1, :]\n",
    "        out = self.hidden_to_output(h_out)\n",
    "        # out = self.soft_max(out)\n",
    "        \n",
    "        return out, hidden_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ml_Model():\n",
    "    # Hyper-parameters \n",
    "    num_epochs = 10\n",
    "    # warmup_epochs = 2\n",
    "    batch_size = 1\n",
    "    learning_rate = 0.001\n",
    "    # warmup_learning_rate = 0.01\n",
    "\n",
    "    sequence_length = 1\n",
    "\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers = 1, type=\"RNN\",\n",
    "                  bidirectional=False, optimizer=\"Adam\", loss=\"CrossEntropy\", dropout=0.0,\n",
    "                  word2idx=None):\n",
    "        # TODO: instantiate model\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.model = None\n",
    "        self.loss = None\n",
    "\n",
    "        self.word2idx = word2idx\n",
    "\n",
    "        self.model = Torch_Model(input_size, hidden_size, num_classes, num_layers,\n",
    "                                    bidirectional=bidirectional, dropout=dropout, type=type).to(device)\n",
    "\n",
    "        if optimizer == \"Adam\":\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=Ml_Model.learning_rate)\n",
    "        elif optimizer == \"SGD\":\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=Ml_Model.learning_rate)\n",
    "        \n",
    "        if loss == \"CrossEntropy\":\n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "        elif loss == \"MSE\":\n",
    "            self.loss = nn.MSELoss()\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca')\n",
    "        self.embedder = AutoModel.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca')\n",
    "        \n",
    "\n",
    "    def train(self, data):\n",
    "        # TODO: train model GENERIC\n",
    "        # self.model.fit(data, labels)\n",
    "        X = [sent[:-1] for sent in data]\n",
    "        # TODO: padding error\n",
    "        Y = [self.word2idx[word] for sent in data for word in sent[1:]]\n",
    "        Y = torch.tensor(Y)\n",
    "        data_tokenized = self.tokenizer(X, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        data_embedded = self.embedder(**data_tokenized)\n",
    "        X = data_embedded.last_hidden_state[:, 1:-1, :].detach().numpy()\n",
    "        PAD = np.zeros(X.shape[2])\n",
    "\n",
    "        data = Dataset(X, Y, PAD, self.word2idx['<PAD>'])\n",
    "        train_dataloader = torch.utils.data.DataLoader(data, batch_size=Ml_Model.batch_size, shuffle=True).to(device)\n",
    "\n",
    "\n",
    "        if isinstance(self.model, Torch_Model):\n",
    "\n",
    "            for epoch in range(Ml_Model.num_epochs):\n",
    "\n",
    "                for train_input, train_label in tqdm(train_dataloader):\n",
    "                    total_loss_train = 0\n",
    "\n",
    "                    words = train_input.to(device)\n",
    "\n",
    "                    label = train_label.to(device)\n",
    "                    # Forward pass\n",
    "                    outputs, _ = self.model(words)\n",
    "                    self.loss = self.loss(outputs.view(-1, self.num_classes), label.view(-1))\n",
    "                    \n",
    "                    total_loss_train += self.loss.item()\n",
    "\n",
    "\n",
    "                    # Backward and optimize\n",
    "                    self.optimizer.zero_grad()\n",
    "                    self.loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                \n",
    "                epoch_loss = total_loss_train / len(train_dataloader)\n",
    "                \n",
    "                print(f'Epochs: {epoch + 1} | Train Loss: {epoch_loss}')\n",
    "    \n",
    "    # def predict(self, data):\n",
    "    #     # TODO: run model and return predicted output\n",
    "    #     if isinstance(self.model, Torch_Model):\n",
    "    #         with torch.no_grad():\n",
    "    #             words = data.reshape(-1, self.sequence_length, self.input_size).to(device)\n",
    "    #             outputs = self.model(words)\n",
    "    #             # max returns (value ,index)\n",
    "    #             _, predicted = torch.max(outputs.data, 1)\n",
    "    #             return predicted\n",
    "\n",
    "    # def test(self, data, labels):\n",
    "    #     # TODO: calculate score and print them\n",
    "    #     if isinstance(self.model, RNN):\n",
    "    #         with torch.no_grad():\n",
    "    #             n_correct = 0\n",
    "    #             n_samples = 0\n",
    "    #             for i in range(0, len(data), batch_size):\n",
    "    #                 words = data[i:i+batch_size]\n",
    "    #                 words = words.reshape(-1, sequence_length, input_size).to(device)\n",
    "    #                 labels = labels[i:i+batch_size].to(device)\n",
    "    #                 outputs = self.model(words)\n",
    "    #                 # max returns (value ,index)\n",
    "    #                 _, predicted = torch.max(outputs.data, 1)\n",
    "    #                 n_samples += labels.size(0)\n",
    "    #                 n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #             acc = 100.0 * n_correct / n_samples\n",
    "    #             print(f'Accuracy of the network on the 10000 test images: {acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"./processed/val.csv\")\n",
    "data = df[\"tokenized_diacritics_removed\"].apply(eval)\n",
    "# data = list(filter(lambda sent: len(sent) > 2 and min([len(word) for word in  sent]) > 1, data))\n",
    "id2word = {idx:word for idx, word in  enumerate(set(itertools.chain.from_iterable(data)))}\n",
    "word2id = {word:idx for idx, word in id2word.items()}\n",
    "\n",
    "letter_model = Ml_Model(input_size=768, hidden_size=512, num_classes=len(word2id.keys()), type=\"LSTM\", word2idx=word2id)\n",
    "\n",
    "letter_model.train(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_model.predict(torch.tensor([0,1,2,3,4,5], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tashkeel_Model():\n",
    "\n",
    "    def __init__(self, model_type=None):\n",
    "        # TODO: create model and pre processing module\n",
    "\n",
    "        self.model = Ml_Model()\n",
    "        # self.preprocessor = Preprocessing()\n",
    "        pass\n",
    "    \n",
    "    def load_data(self, df):\n",
    "        self.data = df[\"features\"]\n",
    "        self.labels = df[\"labels\"]\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        self.preprocessor.process(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Sample data (replace this with your dataset)\n",
    "sentences = [\n",
    "    \"This is a sample sentence.\",\n",
    "    \"Another example of a sentence.\",\n",
    "    \"PyTorch RNN modeling is fascinating.\"\n",
    "]\n",
    "\n",
    "# Tokenizing and converting sentences to numerical representations (indices)\n",
    "word_to_idx = {}  # Your word to index mapping\n",
    "idx_to_word = {}  # Your index to word mapping\n",
    "\n",
    "# Assuming you have a function to tokenize your sentences and create word-to-index mapping\n",
    "def tokenize_sentence(sentence):\n",
    "    # Tokenize your sentence and convert to indices based on word_to_idx mapping\n",
    "    # Return a list of indices\n",
    "    pass\n",
    "\n",
    "# Convert sentences to indices\n",
    "indexed_sentences = [tokenize_sentence(sentence) for sentence in sentences]\n",
    "\n",
    "# Define an RNN language model\n",
    "class NextWordPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(NextWordPredictor, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        embedded = self.embedding(x)\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_dim)\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "vocab_size = len(word_to_idx)  # Define your vocabulary size\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "model = NextWordPredictor(vocab_size, embedding_dim, hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for sentence in indexed_sentences:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = torch.tensor(sentence[:-1], dtype=torch.long).unsqueeze(0)  # Input sequence\n",
    "        targets = torch.tensor(sentence[1:], dtype=torch.long)  # Target sequence\n",
    "\n",
    "        hidden = model.init_hidden(1)\n",
    "        outputs, _ = model(inputs, hidden)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONT LOOK UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sicom\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, y, pad):\n",
    "    \"\"\"\n",
    "    This is the constructor of the NERDataset\n",
    "    Inputs:\n",
    "    - x: a list of lists where each list contains the ids of the tokens\n",
    "    - y: a list of lists where each list contains the label of each token in the sentence\n",
    "    - pad: the id of the <PAD> token (to be used for padding all sentences and labels to have the same length)\n",
    "    \"\"\"\n",
    "    ##################### TODO: create two tensors one for x and the other for labels ###############################\n",
    "    # padding all sentences and labels to have the same length\n",
    "    max_len = max([len(sentence) for sentence in x])\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "      x[i] = torch.cat((x[i], torch.zeros(max_len - len(x[i]), 768)), 0) \n",
    "      y[i] = y[i] + [0] * (max_len - len(y[i]))\n",
    "      \n",
    "    self.x = torch.stack(x)\n",
    "    self.y = torch.tensor(y)\n",
    "    #################################################################################################################\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    This function should return the length of the dataset (the number of sentences)\n",
    "    \"\"\"\n",
    "    ###################### TODO: return the length of the dataset #############################\n",
    "    return len(self.x)\n",
    "    ###########################################################################################\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    This function returns a subset of the whole dataset\n",
    "    \"\"\"\n",
    "    ###################### TODO: return a tuple of x and y ###################################\n",
    "    return self.x[idx], self.y[idx]\n",
    "    ##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self, input_size=768, hidden_size=50, n_classes=100, bidirectional=False):\n",
    "    \"\"\"\n",
    "    The constructor of our NER model\n",
    "    Inputs:\n",
    "    - vacab_size: the number of unique words\n",
    "    - embedding_dim: the embedding dimension\n",
    "    - n_classes: the number of final classes (tags)\n",
    "    \"\"\"\n",
    "    super(Model, self).__init__()\n",
    "    ####################### TODO: Create the layers of your model #######################################\n",
    "    # (1) Create the embedding layer\n",
    "    \n",
    "\n",
    "    # (2) Create an LSTM layer with hidden size = hidden_size and batch_first = True\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "    # (3) Create a linear layer with number of neorons = n_classes\n",
    "    self.linear = nn.Linear(hidden_size * (2 if bidirectional else 1), n_classes)\n",
    "    #####################################################################################################\n",
    "\n",
    "  def forward(self, X):\n",
    "    \"\"\"\n",
    "    This function does the forward pass of our model\n",
    "    Inputs:\n",
    "    - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "    Returns:\n",
    "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    final_output = None\n",
    "    ######################### TODO: implement the forward pass ####################################\n",
    "    final_output, hidden = self.lstm(X)\n",
    "    final_output = self.linear(final_output)\n",
    "    ###############################################################################################\n",
    "    return final_output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, n_classes, batch_size=512, epochs=5, learning_rate=0.01):\n",
    "  \"\"\"\n",
    "  This function implements the training logic\n",
    "  Inputs:\n",
    "  - model: the model ot be trained\n",
    "  - train_dataset: the training set of type NERDataset\n",
    "  - batch_size: integer represents the number of examples per step\n",
    "  - epochs: integer represents the total number of epochs (full training pass)\n",
    "  - learning_rate: the learning rate to be used by the optimizer\n",
    "  \"\"\"\n",
    "\n",
    "  ############################## TODO: replace the Nones in the following code ##################################\n",
    "  \n",
    "  # (1) create the dataloader of the training set (make the shuffle=True)\n",
    "  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  # (2) make the criterion cross entropy loss\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  # (3) create the optimizer (Adam)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # GPU configuration\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "  if use_cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "  for epoch_num in range(epochs):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "      # (4) move the train input to the device\n",
    "      train_input = train_input.to(device)\n",
    "\n",
    "      # (5) move the train label to the device\n",
    "      train_label = train_label.to(device)\n",
    "\n",
    "\n",
    "      # (6) do the forward pass\n",
    "      output, _ = model(train_input)\n",
    "      output = output.to(device)\n",
    "      \n",
    "      # (7) loss calculation (you need to think in this part how to calculate the loss correctly)\n",
    "      # -1 is ignore \n",
    "      batch_loss = criterion(output.view(-1, n_classes), train_label.view(-1))\n",
    "    \n",
    "\n",
    "      # (8) append the batch loss to the total_loss_train\n",
    "      total_loss_train += batch_loss.item()\n",
    "      \n",
    "      # (9) calculate the batch accuracy (just add the number of correct predictions)\n",
    "      acc = (output.argmax(dim=-1) == train_label).sum().item()\n",
    "      total_acc_train += acc\n",
    "\n",
    "      # (10) zero your gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # (11) do the backward pass\n",
    "      batch_loss.backward(retain_graph=True)\n",
    "\n",
    "      # (12) update the weights with your optimizer\n",
    "      optimizer.step()\n",
    "      \n",
    "    # epoch loss\n",
    "    epoch_loss = total_loss_train / len(train_dataset)\n",
    "\n",
    "    # (13) calculate the accuracy\n",
    "    epoch_acc = total_acc_train / (len(train_dataset) * train_dataset[0][0].shape[0])\n",
    "\n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
    "        | Train Accuracy: {epoch_acc}\\n')\n",
    "\n",
    "  ##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, batch_size=512):\n",
    "  \"\"\"\n",
    "  This function takes a NER model and evaluates its performance (accuracy) on a test data\n",
    "  Inputs:\n",
    "  - model: a NER model\n",
    "  - test_dataset: dataset of type NERDataset\n",
    "  \"\"\"\n",
    "  ########################### TODO: Replace the Nones in the following code ##########################\n",
    "\n",
    "  # (1) create the test data loader\n",
    "  test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "  # GPU Configuration\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "  if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "  total_acc_test = 0\n",
    "  \n",
    "  # (2) disable gradients\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for test_input, test_label in tqdm(test_dataloader):\n",
    "      # (3) move the test input to the device\n",
    "      test_label = test_label.to(device)\n",
    "\n",
    "      # (4) move the test label to the device\n",
    "      test_input = test_input.to(device)\n",
    "\n",
    "      # (5) do the forward pass\n",
    "      output, _ = model(test_input)\n",
    "\n",
    "      # accuracy calculation (just add the correct predicted items to total_acc_test)\n",
    "      acc = (output.argmax(dim=-1) == test_label).sum().item()\n",
    "      total_acc_test += acc\n",
    "    \n",
    "    # (6) calculate the over all accuracy\n",
    "    total_acc_test /= (len(test_dataset) * test_dataset[0][0].shape[0])\n",
    "  ##################################################################################################\n",
    "\n",
    "  \n",
    "  print(f'\\nTest Accuracy: {total_acc_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_cleaned</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>diacritics</th>\n",
       "      <th>word_with_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .</td>\n",
       "      <td>['قَوْلُهُ', 'وَلَا', 'تُكْرَهُ', 'ضِيَافَتُهُ']</td>\n",
       "      <td>['قوله', 'ولا', 'تكره', 'ضيافته']</td>\n",
       "      <td>قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...</td>\n",
       "      <td>[('قوله', tensor([[-5.7860e-05,  7.6122e-01,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "      <td>['الْفَرْقُ', 'الثَّالِثُ', 'وَالثَّلَاثُونَ',...</td>\n",
       "      <td>['الفرق', 'الثالث', 'والثلاثون', 'بين', 'قاعدة...</td>\n",
       "      <td>الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...</td>\n",
       "      <td>[[14, 6, 0, 6, 2], [14, 14, 14, 14, 4, 2], [0,...</td>\n",
       "      <td>[('الفرق', tensor([[-8.2446e-06,  7.6140e-01, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "      <td>['قَوْلُهُ', 'وَهُوَ', 'أَيْ', 'الْبَيْعُ', 'ب...</td>\n",
       "      <td>['قوله', 'وهو', 'أي', 'البيع', 'بالمعنى', 'الث...</td>\n",
       "      <td>قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...</td>\n",
       "      <td>[[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...</td>\n",
       "      <td>[('قوله', tensor([[-5.7860e-05,  7.6122e-01,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "      <td>['إذْ', 'الْمُقَابَلَةُ', 'لَا', 'تَصْدُقُ', '...</td>\n",
       "      <td>['إذ', 'المقابلة', 'لا', 'تصدق', 'على', 'العقد...</td>\n",
       "      <td>إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...</td>\n",
       "      <td>[[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...</td>\n",
       "      <td>[('إذ', tensor([[-2.3214e-05,  7.6133e-01,  4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "      <td>['وَقَدْ', 'يُجْعَلُ', 'كَلَامُهُ', 'عَلَى', '...</td>\n",
       "      <td>['وقد', 'يجعل', 'كلامه', 'على', 'حذف', 'مضاف',...</td>\n",
       "      <td>وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...</td>\n",
       "      <td>[[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...</td>\n",
       "      <td>[('وقد', tensor([[-3.2933e-04,  7.6013e-01,  7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0   \n",
       "0              قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ .  \\\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...   \n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...   \n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...   \n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...   \n",
       "\n",
       "                                           tokenized   \n",
       "0   ['قَوْلُهُ', 'وَلَا', 'تُكْرَهُ', 'ضِيَافَتُهُ']  \\\n",
       "1  ['الْفَرْقُ', 'الثَّالِثُ', 'وَالثَّلَاثُونَ',...   \n",
       "2  ['قَوْلُهُ', 'وَهُوَ', 'أَيْ', 'الْبَيْعُ', 'ب...   \n",
       "3  ['إذْ', 'الْمُقَابَلَةُ', 'لَا', 'تَصْدُقُ', '...   \n",
       "4  ['وَقَدْ', 'يُجْعَلُ', 'كَلَامُهُ', 'عَلَى', '...   \n",
       "\n",
       "                                   tokenized_cleaned   \n",
       "0                  ['قوله', 'ولا', 'تكره', 'ضيافته']  \\\n",
       "1  ['الفرق', 'الثالث', 'والثلاثون', 'بين', 'قاعدة...   \n",
       "2  ['قوله', 'وهو', 'أي', 'البيع', 'بالمعنى', 'الث...   \n",
       "3  ['إذ', 'المقابلة', 'لا', 'تصدق', 'على', 'العقد...   \n",
       "4  ['وقد', 'يجعل', 'كلامه', 'على', 'حذف', 'مضاف',...   \n",
       "\n",
       "                                             cleaned   \n",
       "0                قَوْلُهُ وَلَا تُكْرَهُ ضِيَافَتُهُ  \\\n",
       "1  الْفَرْقُ الثَّالِثُ وَالثَّلَاثُونَ بَيْنَ قَ...   \n",
       "2  قَوْلُهُ وَهُوَ أَيْ الْبَيْعُ بِالْمَعْنَى ال...   \n",
       "3  إذْ الْمُقَابَلَةُ لَا تَصْدُقُ عَلَى الْعَقْد...   \n",
       "4  وَقَدْ يُجْعَلُ كَلَامُهُ عَلَى حَذْفِ مُضَافٍ...   \n",
       "\n",
       "                                          diacritics   \n",
       "0  [[0, 6, 2, 2], [0, 0, 14], [2, 6, 0, 2], [4, 0...  \\\n",
       "1  [[14, 6, 0, 6, 2], [14, 14, 14, 14, 4, 2], [0,...   \n",
       "2  [[0, 6, 2, 2], [0, 2, 0], [0, 6], [14, 6, 0, 6...   \n",
       "3  [[14, 6], [14, 6, 2, 0, 14, 0, 0, 2], [0, 14],...   \n",
       "4  [[0, 0, 6], [2, 6, 0, 2], [0, 0, 14, 2, 2], [0...   \n",
       "\n",
       "                                   word_with_context  \n",
       "0  [('قوله', tensor([[-5.7860e-05,  7.6122e-01,  ...  \n",
       "1  [('الفرق', tensor([[-8.2446e-06,  7.6140e-01, ...  \n",
       "2  [('قوله', tensor([[-5.7860e-05,  7.6122e-01,  ...  \n",
       "3  [('إذ', tensor([[-2.3214e-05,  7.6133e-01,  4....  \n",
       "4  [('وقد', tensor([[-3.2933e-04,  7.6013e-01,  7...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./processed/val.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id2word ...\n",
      "word2id ...\n",
      "starting embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 608/6492 [02:57<28:39,  3.42it/s]  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1867776 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting embedding...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[1;32m---> 24\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprogress_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     25\u001b[0m Y \u001b[38;5;241m=\u001b[39m [ [word2id[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent[\u001b[38;5;241m1\u001b[39m:]] \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4517\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4522\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4524\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4525\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4624\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    799\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting embedding...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[1;32m---> 24\u001b[0m train_data \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: embedder(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mx)\u001b[38;5;241m.\u001b[39mlast_hidden_state[:,\u001b[38;5;241m1\u001b[39m, :]) \n\u001b[0;32m     25\u001b[0m Y \u001b[38;5;241m=\u001b[39m [ [word2id[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent[\u001b[38;5;241m1\u001b[39m:]] \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1012\u001b[0m )\n\u001b[1;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    598\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m         output_attentions,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    536\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    537\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 539\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\pytorch_utils.py:242\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 551\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:451\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 451\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:80] data. DefaultCPUAllocator: not enough memory: you tried to allocate 1867776 bytes."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./processed/val.csv\")\n",
    "\n",
    "data = df[\"tokenized_cleaned\"].apply(eval)\n",
    "data = list(filter(lambda sent: len(sent) > 1, data))\n",
    "id2word = {idx+1:word for idx, word in  enumerate(set(itertools.chain.from_iterable(data)))}\n",
    "id2word[0] = '<PAD>'\n",
    "print(\"id2word ...\")\n",
    "\n",
    "word2id = {word:idx for idx, word in id2word.items()}\n",
    "print(\"word2id ...\")\n",
    "\n",
    "context_model = Model(hidden_size=256, n_classes=len(word2id.keys()), bidirectional=True).to(device)\n",
    "\n",
    "X  = pd.DataFrame()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca')\n",
    "embedder = AutoModel.from_pretrained('CAMeL-Lab/bert-base-arabic-camelbert-ca')\n",
    "X[0] = [tokenizer(sent[:-1], return_tensors=\"pt\", padding=True) for sent in data]\n",
    "\n",
    "print(\"starting embedding...\")\n",
    "\n",
    "tqdm.pandas()\n",
    "train_data = X[0].progress_apply(lambda x: embedder(**x).last_hidden_state[:,1, :]) \n",
    "Y = [ [word2id[word] for word in sent[1:]] for sent in data]\n",
    "print(\"starting training...\")\n",
    "\n",
    "train_dataset = Dataset(train_data, Y, np.zeros(768))\n",
    "\n",
    "train(context_model, train_dataset, n_classes=len(word2id.keys()), batch_size=20, epochs=3, learning_rate=0.01)\n",
    "\n",
    "pickle.dump(context_model, open(\"./models/context_model_bi.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./processed/val.csv\")\n",
    "\n",
    "data = df[\"tokenized_diacritics_removed\"].apply(eval)\n",
    "data = data[1000: 1250]\n",
    "data = list(filter(lambda sent: len(sent) > 1, data))\n",
    "id2word = {idx+1:word for idx, word in  enumerate(set(itertools.chain.from_iterable(data)))}\n",
    "id2word[0] = '<PAD>'\n",
    "word2id = {word:idx for idx, word in id2word.items()}\n",
    "\n",
    "\n",
    "X = [sent[:-1] for sent in data]\n",
    "print(\"starting embedding...\")\n",
    "\n",
    "X = [ embedder(**tokenizer(sent, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)).last_hidden_state[:,1, :] for sent in X]\n",
    "Y = [ [word2id[word] for word in sent[1:]] for sent in data]\n",
    "print(\"starting training...\")\n",
    "\n",
    "train_dataset = Dataset(X, Y, np.zeros(768))\n",
    "\n",
    "evaluate(context_model, train_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump(context_model, open(\"./models/context_model.pkl\", \"wb\"))\n",
    "pickle.dump(word2id, open(\"./models/word2id.pkl\", \"wb\"))\n",
    "pickle.dump(id2word, open(\"./models/id2word.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tashkeel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, e, y, pad=None):\n",
    "    \"\"\"\n",
    "    This is the constructor of the NERDataset\n",
    "    Inputs:\n",
    "    - x: a list of lists where each list contains the ids of the tokens\n",
    "    - y: a list of lists where each list contains the label of each token in the sentence\n",
    "    - pad: the id of the <PAD> token (to be used for padding all sentences and labels to have the same length)\n",
    "    \"\"\"\n",
    "    ##################### TODO: create two tensors one for x and the other for labels ###############################\n",
    "    # padding all sentences and labels to have the same length\n",
    "    # max_len = max([len(sentence) for sentence in x])\n",
    "    # for i in range(len(x)):\n",
    "      # x[i] = x[i] + [pad] * (max_len - len(x[i]))  \n",
    "      # y[i] = y[i] + [14] * (max_len - len(y[i]))\n",
    "    self.x = torch.tensor(x)\n",
    "    self.e = torch.tensor(e)\n",
    "    print(e.shape, self.e.shape)\n",
    "    self.y = torch.tensor(y)\n",
    "    #################################################################################################################\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    This function should return the length of the dataset (the number of sentences)\n",
    "    \"\"\"\n",
    "    ###################### TODO: return the length of the dataset #############################\n",
    "    return len(self.x)\n",
    "    ###########################################################################################\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    This function returns a subset of the whole dataset\n",
    "    \"\"\"\n",
    "    ###################### TODO: return a tuple of x and y ###################################\n",
    "    return self.x[idx], self.e[idx], self.y[idx]\n",
    "    ##########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    diacritic2id = pickle.load(open(\"./assets/diacritic2id.pickle\", \"rb\"))\n",
    "    arabic_letters = list(pickle.load(open(\"./assets/arabic_letters.pickle\", \"rb\")))\n",
    "\n",
    "    data = data.apply(lambda sent: [[arabic_letters.index(letter) for letter in word] for word in sent])\n",
    "    labels = df[\"diacritics\"].apply(eval)\n",
    "\n",
    "    data = data.explode().to_list()\n",
    "    labels = labels.explode().to_list()\n",
    "    train_data = zip(data, labels)\n",
    "\n",
    "    train_data = list(filter(lambda sent: isinstance(sent[0], list), train_data))\n",
    "\n",
    "    data, labels = zip(*train_data) \n",
    "\n",
    "    data = [list(word) for word in data]\n",
    "    labels = [list(diacritic) for diacritic in labels]\n",
    "\n",
    "    # Convert words and labels to numerical sequences\n",
    "    max_word_len = max(len(word) for word in data)\n",
    "    X = np.zeros((len(data), max_word_len, len(arabic_letters)+1), dtype=np.float32)\n",
    "    y = np.zeros((len(data), max_word_len), dtype=np.int64)\n",
    "\n",
    "    print(X.shape, y.shape)\n",
    "    for i, word in enumerate(data):\n",
    "        for j, char in enumerate(word):\n",
    "            X[i, j, char] = 1\n",
    "            y[i, j] = labels[i][j]\n",
    "\n",
    "\n",
    "    train_data = Dataset(X, y)\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./processed/val.csv\")\n",
    "data = df[\"tokenized_diacritics_removed\"].apply(eval)\n",
    "\n",
    "load_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model = Model(input_size=37, hidden_size=512, n_classes=15, bidirectional=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(context_model, train_data, n_classes=len(diacritic2id.keys()), batch_size=100, epochs=10, learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "\n",
    "    # (1) create the test data loader\n",
    "\n",
    "    # GPU Configuration\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    # (2) disable gradients\n",
    "    with torch.no_grad():\n",
    "        data = torch.tensor(data).to(device)\n",
    "        output, _ = model(data)\n",
    "\n",
    "    \n",
    "    ##################################################################################################\n",
    "    return output.argmax(dim=-1).cpu().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"الفرق الثالث والثلاثون بين قاعدة تقدم الحكم عل\"\n",
    "sent = sent.split()\n",
    "sent = [[arabic_letters.index(letter) for letter in word] for word in sent]\n",
    "\n",
    "# Convert words and labels to numerical sequences\n",
    "max_word_len = max(len(word) for word in sent)\n",
    "X = np.zeros((len(sent), max_word_len, len(arabic_letters)+1), dtype=np.float32)\n",
    "y = np.zeros((len(sent), max_word_len), dtype=np.int64)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "for i, word in enumerate(sent):\n",
    "    for j, char in enumerate(word):\n",
    "        X[i, j, char] = 1\n",
    "        # y[i, j] = labels[i][j]\n",
    "\n",
    "\n",
    "pred = predict(context_model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2diacritic = {idx:diacritic for diacritic, idx in diacritic2id.items()}\n",
    "gomla = \"\"\n",
    "for i, word in enumerate(sent):\n",
    "    for j, char in enumerate(word):\n",
    "        gomla += arabic_letters[char] + id2diacritic[pred[i][j]]\n",
    "        \n",
    "    gomla += \" \"\n",
    "gomla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(context_model, open(\"./models/tashkeel_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./processed/val.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[\"diacritics\"].apply(eval)\n",
    "data = data[\"word_with_context\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data, labels):\n",
    "    diacritic2id = pickle.load(open(\"./assets/diacritic2id.pickle\", \"rb\"))\n",
    "    arabic_letters = list(pickle.load(open(\"./assets/arabic_letters.pickle\", \"rb\")))\n",
    "\n",
    "    data = data.apply(lambda sent: [([arabic_letters.index(letter) for letter in word[0]], word[1]) for word in sent])\n",
    "\n",
    "    data = data.explode().to_list()\n",
    "    labels = labels.explode().to_list()\n",
    "    train_data = zip(data, labels)\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for word in train_data:\n",
    "        try:\n",
    "            if isinstance(word[0][0], list):\n",
    "                cleaned_data.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    # train_data = list(filter(lambda sent: tensor(sent[0][0]))), train_data))\n",
    "    data, labels = zip(*cleaned_data)\n",
    "\n",
    "    data = [(list(word[0]),word[1]) for word in data]\n",
    "    labels = [list(diacritic) for diacritic in labels]\n",
    "\n",
    "    # Convert words and labels to numerical sequences\n",
    "    max_word_len = max(len(word[0]) for word in data)\n",
    "    X = torch.zeros((len(data), max_word_len, len(arabic_letters)+1), dtype=torch.float32).cpu()\n",
    "    y = torch.zeros((len(data), max_word_len), dtype=torch.int64).cpu()\n",
    "\n",
    "    for i, word in enumerate(data):\n",
    "        for j, char in enumerate(word):\n",
    "            try:\n",
    "                X[i, j, tensor(char, dtype=torch.long)] = 1\n",
    "                y[i, j] = labels[i][j]\n",
    "            except Exception as e:\n",
    "                y[i, j] = 14\n",
    "\n",
    "\n",
    "    E = torch.cat([word[1] for word in data])\n",
    "\n",
    "    train_data = Dataset(X, E, y)\n",
    "\n",
    "    return train_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tashkeel_model = Model(input_size=37, hidden_size=128, n_classes=15).to(device)\n",
    "tashkeel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, n_classes, batch_size=512, epochs=5, learning_rate=0.01):\n",
    "  \"\"\"\n",
    "  This function implements the training logic\n",
    "  Inputs:\n",
    "  - model: the model ot be trained\n",
    "  - train_dataset: the training set of type NERDataset\n",
    "  - batch_size: integer represents the number of examples per step\n",
    "  - epochs: integer represents the total number of epochs (full training pass)\n",
    "  - learning_rate: the learning rate to be used by the optimizer\n",
    "  \"\"\"\n",
    "\n",
    "  ############################## TODO: replace the Nones in the following code ##################################\n",
    "  \n",
    "  # (1) create the dataloader of the training set (make the shuffle=True)\n",
    "  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  # (2) make the criterion cross entropy loss\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  # (3) create the optimizer (Adam)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # GPU configuration\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "  if use_cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "  for epoch_num in range(epochs):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    for train_input, hidden, train_label in tqdm(train_dataloader):\n",
    "      # (4) move the train input to the device\n",
    "      train_input = train_input.to(device)\n",
    "\n",
    "      # (5) move the train label to the device\n",
    "      train_label = train_label.to(device)\n",
    "\n",
    "\n",
    "      # (6) do the forward pass\n",
    "      output, _ = model(train_input, (hidden.unsqueeze(0), torch.zeros_like(hidden.unsqueeze(0))))\n",
    "      output = output.to(device)\n",
    "      \n",
    "      # (7) loss calculation (you need to think in this part how to calculate the loss correctly)\n",
    "      # -1 is ignore \n",
    "      batch_loss = criterion(output.view(-1, n_classes), train_label.view(-1))\n",
    "    \n",
    "\n",
    "      # (8) append the batch loss to the total_loss_train\n",
    "      total_loss_train += batch_loss.item()\n",
    "      \n",
    "      # (9) calculate the batch accuracy (just add the number of correct predictions)\n",
    "      acc = (output.argmax(dim=-1) == train_label).sum().item()\n",
    "      total_acc_train += acc\n",
    "\n",
    "      # (10) zero your gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # (11) do the backward pass\n",
    "      batch_loss.backward(retain_graph=True)\n",
    "\n",
    "      # (12) update the weights with your optimizer\n",
    "      optimizer.step()\n",
    "      \n",
    "    # epoch loss\n",
    "    epoch_loss = total_loss_train / len(train_dataset)\n",
    "\n",
    "    # (13) calculate the accuracy\n",
    "    epoch_acc = total_acc_train / (len(train_dataset) * train_dataset[0][0].shape[0])\n",
    "\n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
    "        | Train Accuracy: {epoch_acc}\\n')\n",
    "\n",
    "  ##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self, input_size=768, hidden_size=50, n_classes=100, bidirectional=False):\n",
    "    \"\"\"\n",
    "    The constructor of our NER model\n",
    "    Inputs:\n",
    "    - vacab_size: the number of unique words\n",
    "    - embedding_dim: the embedding dimension\n",
    "    - n_classes: the number of final classes (tags)\n",
    "    \"\"\"\n",
    "    super(Model, self).__init__()\n",
    "    ####################### TODO: Create the layers of your model #######################################\n",
    "    # (1) Create the embedding layer\n",
    "    \n",
    "\n",
    "    # (2) Create an LSTM layer with hidden size = hidden_size and batch_first = True\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "    # (3) Create a linear layer with number of neorons = n_classes\n",
    "    self.linear = nn.Linear(hidden_size * (2 if bidirectional else 1), n_classes)\n",
    "    #####################################################################################################\n",
    "\n",
    "  def forward(self, X, hidden=None):\n",
    "    \"\"\"\n",
    "    This function does the forward pass of our model\n",
    "    Inputs:\n",
    "    - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "    Returns:\n",
    "    - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "    \"\"\"\n",
    "\n",
    "    final_output = None\n",
    "    ######################### TODO: implement the forward pass ####################################\n",
    "    final_output, hidden = self.lstm(X, hidden)\n",
    "    final_output = self.linear(final_output)\n",
    "    ###############################################################################################\n",
    "    return final_output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(tashkeel_model, train_data, n_classes=15, batch_size=200, epochs=10, learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tashkeel_model, open(\"./models/tashkeel_model_context.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size=768, hidden_size=50, n_classes=100, bidirectional=False):\n",
    "        \"\"\"\n",
    "        The constructor of our NER model\n",
    "        Inputs:\n",
    "        - vacab_size: the number of unique words\n",
    "        - embedding_dim: the embedding dimension\n",
    "        - n_classes: the number of final classes (tags)\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "                            batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(\n",
    "            hidden_size * (2 if bidirectional else 1), n_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        This function does the forward pass of our model\n",
    "        Inputs:\n",
    "        - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "        Returns:\n",
    "        - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        final_output, hidden = self.lstm(X)\n",
    "        final_output = self.linear(final_output)\n",
    "\n",
    "        return final_output, hidden\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Context_Model(nn.Module):\n",
    "    def __init__(self, input_size=768, hidden_size=50, n_classes=100, bidirectional=False):\n",
    "        \"\"\"\n",
    "        The constructor of our NER model\n",
    "        Inputs:\n",
    "        - vacab_size: the number of unique words\n",
    "        - embedding_dim: the embedding dimension\n",
    "        - n_classes: the number of final classes (tags)\n",
    "        \"\"\"\n",
    "        super(Context_Model, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size,\n",
    "                            batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        self.linear = nn.Linear(\n",
    "            hidden_size * (2 if bidirectional else 1), n_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        This function does the forward pass of our model\n",
    "        Inputs:\n",
    "        - sentences: tensor of shape (batch_size, max_length)\n",
    "\n",
    "        Returns:\n",
    "        - final_output: tensor of shape (batch_size, max_length, n_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        final_output, hidden = self.lstm(X)\n",
    "        final_output = self.linear(final_output)\n",
    "\n",
    "        return final_output, hidden\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_model = pickle.load(open(\"./models/context_model.pkl\", \"rb\"))\n",
    "new_context_model = Context_Model()\n",
    "new_context_model.__dict__ = context_model.__dict__\n",
    "# new_context_model.load_state_dict(context_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dumps(new_context_model, open(\"./models/context_model_new.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_context_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
