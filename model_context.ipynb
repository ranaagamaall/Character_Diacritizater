{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sicom\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, y, pad=None):\n",
    "    \"\"\"\n",
    "    This is the constructor of the NERDataset\n",
    "    Inputs:\n",
    "    - x: a list of lists where each list contains the ids of the tokens\n",
    "    - y: a list of lists where each list contains the label of each token in the sentence\n",
    "    - pad: the id of the <PAD> token (to be used for padding all sentences and labels to have the same length)\n",
    "    \"\"\"\n",
    "    # padding all sentences and labels to have the same length\n",
    "    x = list(x)\n",
    "    y = list(y)\n",
    "    max_len = max([len(sentence) for sentence in x])\n",
    "    for i in range(len(x)):\n",
    "      x[i] = torch.cat((tensor(x[i]), torch.zeros((max_len - len(x[i]), 53))))\n",
    "      y[i] = tensor(y[i] + [15] * (max_len - len(y[i])))\n",
    "    self.x = torch.stack(x)\n",
    "    self.y = torch.stack(y)\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"\n",
    "    This function should return the length of the dataset (the number of sentences)\n",
    "    \"\"\"\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    This function returns a subset of the whole dataset\n",
    "    \"\"\"\n",
    "    return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data, labels):\n",
    "\n",
    "    data = data.explode().to_list()\n",
    "    labels = labels.explode().to_list()\n",
    "    train_data = zip(data, labels)\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for word in train_data:\n",
    "        try:\n",
    "            if isinstance(word[0], list):\n",
    "                cleaned_data.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    data, labels = zip(*cleaned_data)\n",
    "\n",
    "    train_data = Dataset(data, labels)\n",
    "\n",
    "    return train_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self, input_size=768, hidden_size=50, n_classes=100, bidirectional=False):\n",
    "    super(Model, self).__init__()\n",
    "\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "    self.linear = nn.Linear(hidden_size * (2 if bidirectional else 1), n_classes)\n",
    "\n",
    "  def forward(self, X, hidden=None):\n",
    "\n",
    "    final_output, hidden = self.lstm(X, hidden)\n",
    "    final_output = self.linear(final_output)\n",
    "\n",
    "    return final_output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, n_classes, batch_size=512, epochs=5, learning_rate=0.01):\n",
    "  # (1) create the dataloader of the training set (make the shuffle=True)\n",
    "  train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  # (2) make the criterion cross entropy loss\n",
    "  criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "  # (3) create the optimizer (Adam)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # GPU configuration\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "  if use_cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "  for epoch_num in range(epochs):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    for train_input, train_label in tqdm(train_dataloader):\n",
    "      # (4) move the train input to the device\n",
    "      train_input = train_input.to(device)\n",
    "\n",
    "      # (5) move the train label to the device\n",
    "      train_label = train_label.to(device)\n",
    "\n",
    "\n",
    "      # (6) do the forward pass\n",
    "      output, _ = model(train_input)\n",
    "      output = output.to(device)\n",
    "      \n",
    "      # (7) loss calculation (you need to think in this part how to calculate the loss correctly)\n",
    "      # -1 is ignore \n",
    "      batch_loss = criterion(output.view(-1, n_classes), train_label.view(-1))\n",
    "    \n",
    "\n",
    "      # (8) append the batch loss to the total_loss_train\n",
    "      total_loss_train += batch_loss.item()\n",
    "      \n",
    "      # (9) calculate the batch accuracy (just add the number of correct predictions)\n",
    "      acc = (output.argmax(dim=-1) == train_label).sum().item()\n",
    "      total_acc_train += acc\n",
    "\n",
    "      # (10) zero your gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # (11) do the backward pass\n",
    "      batch_loss.backward(retain_graph=True)\n",
    "\n",
    "      # (12) update the weights with your optimizer\n",
    "      optimizer.step()\n",
    "      \n",
    "    # epoch loss\n",
    "    epoch_loss = total_loss_train / len(train_dataset)\n",
    "\n",
    "    # (13) calculate the accuracy\n",
    "    epoch_acc = total_acc_train / (len(train_dataset) * train_dataset[0][0].shape[0])\n",
    "\n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
    "        | Train Accuracy: {epoch_acc}\\n')\n",
    "\n",
    "  ##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_letter_model(model, eval_dataset, batch_size=512):\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        eval_dataset, batch_size=batch_size)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "\n",
    "    total_acc_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in tqdm(test_dataloader):\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "\n",
    "\n",
    "            test_input = test_input.to(device)\n",
    "\n",
    "            output, _ = model(test_input)\n",
    "\n",
    "\n",
    "            acc = (output.argmax(dim=-1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "    print(\n",
    "        f'\\nTest Accuracy: {total_acc_test/(len(eval_dataset) * eval_dataset[0][0].shape[0])}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./processed/train_shwya.csv\")\n",
    "\n",
    "labels = data[\"diacritics\"].apply(eval)\n",
    "data = data[\"features\"].apply(eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Dataset...\")\n",
    "train_data = load_data(data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss: 0.008321050292980282         | Train Accuracy: 0.6466409136714814\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 105.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss: 0.0031591397946338184         | Train Accuracy: 0.7668122270742358\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 96.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss: 0.002592827024818628         | Train Accuracy: 0.823782331205912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tashkeel_model = Model(input_size=36+15+2, hidden_size=512, n_classes=16).to(device)\n",
    "\n",
    "\n",
    "train(tashkeel_model, train_data, n_classes=16, batch_size=200, epochs=3, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss: 0.0018052597813931414         | Train Accuracy: 0.7711454484380249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(tashkeel_model, train_data, n_classes=16, batch_size=500, epochs=1, learning_rate=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tashkeel_model, open(\"./models/demo.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tashkeel_model = pickle.load(open(\"./models/demo.pickle\", \"rb\"))\n",
    "# tashkeel_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./processed/train_sample.csv\")\n",
    "\n",
    "labels = data[\"diacritics\"].apply(eval)\n",
    "data = data[\"features\"].apply(eval)\n",
    "\n",
    "print(\"Creating Dataset...\")\n",
    "train_data = load_data(data, labels)\n",
    "\n",
    "eval_letter_model(tashkeel_model, train_data, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pred_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, x, pad=None):\n",
    "    x = list(x)\n",
    "    max_len = max([len(sentence) for sentence in x])\n",
    "    for i in range(len(x)):\n",
    "      x[i] = torch.cat((tensor(x[i], dtype=torch.float32), torch.zeros((max_len - len(x[i]), 53))))\n",
    "    self.x = torch.stack(x)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pred_data(data):\n",
    "\n",
    "    data = data.explode().to_list()\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for word in data:\n",
    "        try:\n",
    "            if isinstance(word[0], list):\n",
    "                cleaned_data.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    data = cleaned_data\n",
    "\n",
    "    train_data = Pred_Dataset(data)\n",
    "\n",
    "    return train_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_letter_model(model, eval_dataset):\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        eval_dataset, batch_size=1)\n",
    "\n",
    "    out_preds = []\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input in tqdm(test_dataloader):\n",
    "\n",
    "            test_input = test_input.to(device)\n",
    "\n",
    "            output, _ = model(test_input)\n",
    "\n",
    "            outputs = output.argmax(dim=-1)\n",
    "\n",
    "            for i in range(len(test_input[0])):\n",
    "                if test_input[0][i].sum() > 0:\n",
    "                    out_preds.append(outputs[0][i].item())\n",
    "\n",
    "    return out_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./processed/testing.csv\")\n",
    "\n",
    "data = data[\"features\"].apply(eval)\n",
    "test_data = load_pred_data(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104788/104788 [05:01<00:00, 347.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "417359"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pred_letter_model(tashkeel_model, test_data)\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>15</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7027</th>\n",
       "      <td>15</td>\n",
       "      <td>7027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7058</th>\n",
       "      <td>15</td>\n",
       "      <td>7058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>15</td>\n",
       "      <td>7682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>15</td>\n",
       "      <td>7757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398865</th>\n",
       "      <td>15</td>\n",
       "      <td>398865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404551</th>\n",
       "      <td>15</td>\n",
       "      <td>404551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415906</th>\n",
       "      <td>15</td>\n",
       "      <td>415906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415979</th>\n",
       "      <td>15</td>\n",
       "      <td>415979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416050</th>\n",
       "      <td>15</td>\n",
       "      <td>416050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label      ID\n",
       "161        15     161\n",
       "7027       15    7027\n",
       "7058       15    7058\n",
       "7682       15    7682\n",
       "7757       15    7757\n",
       "...       ...     ...\n",
       "398865     15  398865\n",
       "404551     15  404551\n",
       "415906     15  415906\n",
       "415979     15  415979\n",
       "416050     15  416050\n",
       "\n",
       "[122 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(predictions, columns=[\"label\"])\n",
    "submission[\"ID\"] = submission.index\n",
    "submission[submission.label == 15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"./submission/test6.csv\", index=False)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 210.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from code.preprocessing import PreProcess_sent\n",
    "\n",
    "input_sent = \"قوله ولا تكره ضيافته\"\n",
    "\n",
    "preprocessed, tokenized = PreProcess_sent(input_sent)\n",
    "\n",
    "test_data = load_pred_data(preprocessed)\n",
    "\n",
    "tashkeel_model = pickle.load(open(\"./models/full_accuracy.pickle\", \"rb\"))\n",
    "\n",
    "predictions = pred_letter_model(tashkeel_model, test_data)\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'قَوَلهِ وَلاَ تَكْرٌهِ ضَيْاَفِتُّهُ '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diacritic2id = pickle.load(open(\"./assets/diacritic2id.pickle\", \"rb\"))\n",
    "id2diacritic = {v: k for k, v in diacritic2id.items()}\n",
    "tokenized_one_arr = tokenized.explode().to_list()\n",
    "\n",
    "sentence_diacritized = \"\"\n",
    "i = 0\n",
    "for token in tokenized_one_arr:\n",
    "    for letter in token:\n",
    "        sentence_diacritized += letter + id2diacritic[predictions[i]]\n",
    "        i += 1\n",
    "    sentence_diacritized += \" \"\n",
    "\n",
    "sentence_diacritized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
